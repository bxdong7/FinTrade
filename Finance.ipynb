{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84238775-e617-411b-abf3-ae94943d5a01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install yfinance\n",
    "!pip install numpy-financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a82f5e-f678-4d72-b4f5-f84efa7ff0c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from datetime import datetime, timedelta, date\n",
    "from pandas.tseries.offsets import BDay\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "076dc246-f9bb-4fd5-8466-309c4f5614cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = yf.download('SCHD')\n",
    "df = df.reset_index(drop=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6980b1a-6af0-4096-8fac-65eb1a8a7fac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_annualized_return(invest_dates: List[date], invest_values: List[int], final_portfolio_value: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the annualized return\n",
    "\n",
    "    Args:\n",
    "        invest_dates: a list of investment dates\n",
    "        invest_values: a list of investment in dollars\n",
    "        final_portfolio_value: the portfolio value at the end of investment\n",
    "    \n",
    "    Returns:\n",
    "        annualized_return rate\n",
    "    \"\"\"\n",
    "    # get annualized contributions\n",
    "    annual_contri_d = defaultdict(int)\n",
    "    for invest_date, invest_value in zip(invest_dates, invest_values):\n",
    "        year = invest_date.year\n",
    "        annual_contri_d[year] += invest_value\n",
    "        \n",
    "    annual_contri_list = []\n",
    "    for invest_year in annual_contri_d.keys():\n",
    "        annual_contri_list.append(annual_contri_d[invest_year])\n",
    "\n",
    "    # call irr to calculate return\n",
    "    a = np.array([-1 * invest for invest in annual_contri_list] + [final_portfolio_value])\n",
    "\n",
    "    return npf.irr(a)\n",
    "\n",
    "def calculate_sharpe_ratio(invest_dates: List[date], invest_values: List[int], buy_in_shares: List[int], stock_data : pd.DataFrame, risk_free_rate: Optional[float] = 0.02) -> float:\n",
    "    \"\"\"\n",
    "    Calculate annualized sharpe ratio. Only consider keeping buy-in without any sell.\n",
    "    A year's return rate = (year_end_value - last_year_end_value - investment_in_year) / last_year_end_value\n",
    "\n",
    "    Args:\n",
    "        invest_dates: a list of investment dates\n",
    "        invest_values: a list of investment in dollars\n",
    "        buy_in_shares: \n",
    "        final_portfolio_value: the portfolio value at the end of investment\n",
    "    \n",
    "    \"\"\"\n",
    "    # calculate each year's end value and total investment in a year\n",
    "    yearly_values = {}\n",
    "    yearly_investments = {}\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'date': invest_dates, \n",
    "        'value': invest_values, \n",
    "        'buy_in_share': buy_in_shares\n",
    "    })\n",
    "    df = df.set_index('date')\n",
    "    df['hold_share'] = df['buy_in_share'].cumsum()\n",
    "    min_year = invest_dates[0].year\n",
    "    max_year = invest_dates[-1].year\n",
    "    for year in range(min_year, max_year): # intentionally skip last year because it may not be complete yet\n",
    "        year_df = df[str(year)]\n",
    "        year_end_share = year_df.iloc[-1]['hold_share']\n",
    "        year_end_price = stock_data[str(year)].iloc[-1]['Close']\n",
    "        year_end_value = year_end_share * year_end_price\n",
    "        yearly_values[year] = year_end_value\n",
    "        yearly_invest = year_df['value'].sum()\n",
    "        yearly_investments[year] = yearly_invest\n",
    "    \n",
    "    # calcualate yearly return\n",
    "    yearly_return_rate = []\n",
    "    for year in range(min_year+1, max_year):\n",
    "        last_year_end_value = yearly_values[year-1]\n",
    "        this_year_end_value = yearly_values[year]\n",
    "        this_year_invest = yearly_investments[year]\n",
    "        return_rate = (this_year_end_value - last_year_end_value - this_year_invest) / last_year_end_value\n",
    "        yearly_return_rate.append(return_rate)\n",
    "\n",
    "    # calculate sharpe ratio\n",
    "    yearly_return_rate = np.array(yearly_return_rate)\n",
    "    excess_returns = yearly_return_rate - risk_free_rate\n",
    "    sharpe_ratio = np.mean(excess_returns) / np.std(yearly_return_rate)\n",
    "    \n",
    "    return sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f636ecc-2032-4ea6-b8e5-0c9632be25d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Trade:\n",
    "    ETF_DF = pd.DataFrame(\n",
    "        [(\"VGT\", '2004-01-26' , 0.10, 'Technology Sector'), (\"IVV\",'2000-05-15', 0.03, 'Large-Cap Blend'), \n",
    "               (\"SWPPX\", '1997-05-19', 0.02, 'Large-Cap Blend'), (\"VTI\",'2001-05-24' , 0.03, 'Large Blend'), \n",
    "               (\"DIA\",'1998-01-13', 0.16, 'Large Value'), (\"QQQ\",'1999-03-10', 0.20, 'Large Growth'), (\"IWM\",'2000-05-22', 0.19, 'Small-Cap Blend'), \n",
    "               (\"DBC\",'2006-02-03', 0.85, 'Commodities Broad Basket'), (\"SWTSX\",'1999-06-01', 0.03, 'Large-Cap Blend'), \n",
    "               (\"WFIVX\",'1999-02-01', 0.54, 'Large-Cap Growth'), (\"VNQ\",'2004-09-23', 0.12, 'Real Estate'), (\"SMH\",'2011-12-20', 0.35, 'Semiconductors'), \n",
    "               (\"FNCMX\", '2003-09-25', 0.29, 'Large-Cap Growth'), (\"OEF\", '2000-10-23', 0.20, 'Large Blend'), \n",
    "               (\"MDY\", '1995-05-04', 0.23, 'Mid-Cap Blend'), (\"IWO\",'2000-07-24', 0.23, 'Small Growth'), (\"VUG\", '2004-01-26', 0.04, 'Large-Cap Growth'), \n",
    "               (\"NASDX\", '2000-01-18', 0.50, 'Large Growth'), (\"SDY\", '2005-11-08', 0.35, 'Mid-Cap Value'), \n",
    "               (\"SSO\", '2006-06-19', 0.89, 'Leveraged Large-Cap Blend'), (\"GLD\", '2004-11-18', 0.40, 'Gold') , \n",
    "               (\"XLK\", '1998-12-16', 0.10, 'Technology Sector'), (\"XLV\", '1998-12-16', 0.10, 'Healthcare Sector'), \n",
    "               (\"XLE\", '1998-12-16', 0.10, 'Energy Sector'), (\"IWV\", '2000-05-22', 0.20, 'Large Blend'), (\"VGELX\", '2001-11-12', 0.25, 'Large-Cap Value'),\n",
    "               (\"VINIX\", '1990-07-31', 0.02, 'Large Blend'), (\"AGTHX\", '1973-12-01', 1.39, 'Large-Cap Growth'), \n",
    "               (\"VWO\", '2005-03-04', 0.08, 'Emerging Markets'), (\"VXF\", '2001-12-27', 0.06, 'Mid-Cap Blend'), (\"SCHD\", '2011-10-20', 0.06, 'Large Value'),\n",
    "               (\"VOO\",'2010-09-07' ,0.14, 'Large-Cap Blend'),  ('VIG','2006-04-21' , 0.08, 'Large Blend'), ('IWR', '2001-07-17', 0.18, 'Mid-Cap Blend'),\n",
    "               ('VOE', '2006-08-17', 0.07, 'Mid-Cap Value'), ('VB', '2004-01-26', 0.03, 'Small Blend'), ('VO', '2001-11-12', 0.05, 'Mid-Cap Blend'),\n",
    "               ('SCHA', '2009-11-03' ,0.04, 'Small Blend'), ('VHT', '2004-02-05', 0.10, 'Healthcare Sector'), \n",
    "               ('IHF', '2006-05-01', 0.39, 'Healthcare Sector')],\n",
    "        columns=['ticker', 'inception_date', 'expense_ratio', 'category']\n",
    "    )\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.hist_df = self.__load_data()\n",
    "\n",
    "    def __load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return a df with Date, Ticker, Open, Low, High, Close (all prices are adjusted)\n",
    "        \"\"\"\n",
    "        dfs = []\n",
    "        etfs = self.ETF_DF['ticker'].values\n",
    "        for etf in etfs:\n",
    "            df = yf.download(etf)\n",
    "            df = df.reset_index(drop=False)\n",
    "            df['Adj'] = df['Adj Close'] - df['Close']\n",
    "            df['Adj Open'] = df['Open'] + df['Adj']\n",
    "            df['Adj Low'] = df['Low'] + df['Adj']\n",
    "            df['Adj High'] = df['High'] + df['Adj']\n",
    "            df['Date'] = df['Date'].apply(lambda x: x.date())\n",
    "            df['Ticker'] = etf\n",
    "            df = df[['Date', 'Ticker', 'Adj Open', 'Adj Low', 'Adj High', 'Adj Close']]\n",
    "            df.columns = ['Date', 'Ticker', 'Open', 'Low', 'High', 'Close']\n",
    "            dfs.append(df)\n",
    "\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "        return df\n",
    "    \n",
    "    def __get_trade_period(self, etfs: List[str], start_dt: Optional[date] = None) -> Tuple[date, date]:\n",
    "        \"\"\"\n",
    "        Return the start_dt and end_dt of the trade.\n",
    "        \"\"\"\n",
    "        if start_dt is None:\n",
    "            start_dts = [self.hist_df.loc[self.hist_df['Ticker'] == etf]['Date'].min() for etf in etfs]\n",
    "            start_dt = max(start_dts)\n",
    "\n",
    "        end_dts = [self.hist_df.loc[self.hist_df['Ticker'] == etf]['Date'].max() for etf in etfs]\n",
    "        end_dt = min(end_dts)\n",
    "\n",
    "        return start_dt, end_dt\n",
    "    \n",
    "    def __get_trade_freq(self, freq: str, trading_day: str) -> str:\n",
    "        \"\"\"\n",
    "        freq: weekly/biweekly/monthly\n",
    "        trading_day: MON/TUE/WED/THU/FRI/START/END\n",
    "        \"\"\"\n",
    "        if freq == 'weekly':\n",
    "            freq_s = 'W-' + trading_day\n",
    "        elif freq == 'biweekly':\n",
    "            freq_s = 'SM'\n",
    "            if trading_day == 'START':\n",
    "                freq_s += 'S'\n",
    "        else:\n",
    "            freq_s = 'BM'\n",
    "            if trading_day == 'START':\n",
    "                freq_s += 'S'\n",
    "        \n",
    "        return freq_s\n",
    "    \n",
    "    def __get_trade_days(\n",
    "        self,  \n",
    "        etfs: List[str], \n",
    "        start_dt: Optional[date],\n",
    "        freq: str, \n",
    "        trading_day: str\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get a an array of trading days\n",
    "\n",
    "        Returns:\n",
    "            an np array of dates\n",
    "        \"\"\"\n",
    "        # get start and end_dt\n",
    "        start_dt, end_dt = self.__get_trade_period(etfs, start_dt)\n",
    "\n",
    "        # get freq\n",
    "        if freq == None:\n",
    "            freq_s = 'B'\n",
    "        else:\n",
    "            freq_s = self.__get_trade_freq(freq, trading_day)\n",
    "\n",
    "        # generate dates\n",
    "        dates = pd.date_range(start=start_dt, end=end_dt, freq=freq_s, inclusive='both').date\n",
    "        # find dates that are in the index of hist_df\n",
    "        all_trade_dates = self.hist_df['Date'].values\n",
    "        trade_dates = []\n",
    "        for day in dates:\n",
    "            v = day\n",
    "            while v not in all_trade_dates:\n",
    "                v = v + BDay(1)\n",
    "            trade_dates.append(v)\n",
    "        trade_dates = np.array(trade_dates)\n",
    "        return trade_dates\n",
    "    \n",
    "    def __get_day_price(\n",
    "        self,\n",
    "        day: date,\n",
    "        etfs: List[str],\n",
    "        metric: str\n",
    "    ) -> List[float]:\n",
    "        \"\"\"\n",
    "        Get the price of the etfs on a certain day\n",
    "\n",
    "        Args:\n",
    "            day: date\n",
    "            etfs: Tickers\n",
    "            metric: Open/Low/High/Close\n",
    "        \"\"\"\n",
    "        price_df = self.hist_df.loc[(self.hist_df['Date'] == day) & (self.hist_df['Ticker'].isin(etfs))][['Ticker', metric]]\n",
    "        price_df = price_df.set_index('Ticker')\n",
    "        price_s = price_df[metric]\n",
    "        price_s = price_s[etfs]\n",
    "        return price_s.values.tolist()\n",
    "    \n",
    "    def __calculate_total_value(\n",
    "        self,\n",
    "        day: date,\n",
    "        invest_df: pd.DataFrame\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calculate the total value of all the holdings based on the open price\n",
    "\n",
    "        Args:\n",
    "            day: \n",
    "            invest_df: a pd.DataFrame with Date, etfs and Invest_Value that lists the history of transactions\n",
    "\n",
    "        Returns:\n",
    "            a pd.Series that shows the values of each ETF, indexed by ETF tickers\n",
    "        \"\"\"\n",
    "        # calculate total holding df\n",
    "        holding_df = invest_df.drop(columns=['Date', 'Invest_Value'])\n",
    "        holding_df = pd.DataFrame([holding_df.sum()])\n",
    "        etfs = holding_df.columns\n",
    "        holding_df = holding_df.melt(value_vars=etfs, var_name='Ticker', value_name='Holding')\n",
    "\n",
    "        # join \n",
    "        price_df = self.hist_df.loc[(self.hist_df['Date'] == day) & (self.hist_df['Ticker'].isin(etfs))]\n",
    "        value_df = holding_df.merge(price_df, on='Ticker', how='inner')\n",
    "\n",
    "        # calculate each etf's total value\n",
    "        value_df['Value'] = value_df['Open'] * value_df['Holding']\n",
    "        value_s = pd.Series(value_df['Value'].values, index=value_df['Ticker'].values)\n",
    "        value_s = value_s[etfs]\n",
    "        return value_s\n",
    "\n",
    "    def __calculate_annual_contribution(\n",
    "        self,\n",
    "        invest_df: pd.DataFrame\n",
    "    ) -> np.array:\n",
    "        \"\"\"\n",
    "        Calculate the annual investment contribution value\n",
    "\n",
    "        Args:\n",
    "            invest_df: a pd.DataFrame with Date, etfs and Invest_Value that lists the history of transactions\n",
    "\n",
    "        Returns:\n",
    "            an np array of annual investment\n",
    "        \"\"\"\n",
    "        invest_df = invest_df.copy()\n",
    "        invest_df['year'] = invest_df['Date'].apply(lambda x: x.year)\n",
    "        annual_contri = (\n",
    "            invest_df\n",
    "                .groupby('year')['Invest_Value']\n",
    "                .sum()\n",
    "                .reset_index(drop=False)\n",
    "                .sort_values(by='year')\n",
    "                ['Invest_Value'].values\n",
    "        )\n",
    "        return annual_contri\n",
    "    \n",
    "    def __calculate_annualized_return(\n",
    "        self,\n",
    "        invest_df: pd.DataFrame\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate annualized return based on the investment history and the lastest ETF price\n",
    "\n",
    "        Args:\n",
    "            invest_df: a pd.DataFrame with Date, etfs and Invest_Value that lists the history of transactions\n",
    "        \n",
    "        Returns:\n",
    "            annualized return\n",
    "        \"\"\"\n",
    "        # calculate final_portfolio_value\n",
    "        last_day = self.hist_df['Date'].max()\n",
    "        final_portfolio_value = self.__calculate_total_value(last_day, invest_df).sum()\n",
    "\n",
    "        # get annual contri\n",
    "        annual_contri = self.__calculate_annual_contribution(invest_df)\n",
    "\n",
    "        # call irr to calculate return\n",
    "        a = np.append((-1) * annual_contri, [final_portfolio_value])\n",
    "\n",
    "        return npf.irr(a)\n",
    "    \n",
    "    def __calculate_year_end_value(self, invest_df: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Calculate the year-end value of the portfolio\n",
    "\n",
    "        Args:\n",
    "            invest_df: a pd.DataFrame with Date, etfs and Invest_Value that lists the history of transactions\n",
    "\n",
    "        Returns:\n",
    "            an np array of year-end value\n",
    "        \"\"\"\n",
    "        # get all years\n",
    "        first_year = invest_df['Date'].values[0].year\n",
    "        last_year = invest_df['Date'].values[-1].year\n",
    "\n",
    "        # for each year\n",
    "        year_end_values = []\n",
    "        for year in range(first_year, last_year):\n",
    "            # find last day\n",
    "            last_day = date(year, 12, 31)\n",
    "            # take a sub_df from invest_df\n",
    "            sub_df = invest_df.loc[invest_df['Date'] <= last_day]\n",
    "            last_day = sub_df.iloc[-1]['Date']\n",
    "            # calculate value\n",
    "            value = self.__calculate_total_value(last_day, sub_df).sum()\n",
    "            year_end_values.append(value)\n",
    "\n",
    "        return np.array(year_end_values)\n",
    "    \n",
    "    def __calculate_sharpe_ratio(\n",
    "        self,\n",
    "        invest_df: pd.DataFrame,\n",
    "        risk_free_rate: float = 0.02\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate sharpe ratio based on the investment history and the lastest ETF price\n",
    "\n",
    "        Args:\n",
    "            invest_df: a pd.DataFrame with Date, etfs and Invest_Value that lists the history of transactions\n",
    "        \n",
    "        Returns:\n",
    "            sharpe ratio\n",
    "        \"\"\"\n",
    "        # calculate annual contribution\n",
    "        annual_contris = self.__calculate_annual_contribution(invest_df)\n",
    "\n",
    "        # calculate annual year-end value\n",
    "        annual_values = self.__calculate_year_end_value(invest_df)\n",
    "\n",
    "        # calculate annual return\n",
    "        annual_rates = []\n",
    "        for prev_annual_value, next_annual_contri, next_annual_value in zip(annual_values[:-2], annual_contris[1:-1], annual_values[1:-1]):\n",
    "            annual_rate = (next_annual_value - next_annual_contri - prev_annual_value) / prev_annual_value\n",
    "            annual_rates.append(annual_rate)\n",
    "\n",
    "        # calculate sharpe ratio\n",
    "        annual_rates = np.array(annual_rates)\n",
    "        excess_returns = annual_rates - risk_free_rate\n",
    "        sharpe_ratio = np.mean(excess_returns) / np.std(annual_rates)\n",
    "        return sharpe_ratio\n",
    "    \n",
    "    def __dca_buy(\n",
    "        self,\n",
    "        day: date,\n",
    "        etfs: List[str],\n",
    "        shares: Optional[List[int]] = [2], \n",
    "        amt: Optional[float] = 500,  \n",
    "        weights: Optional[List[float]] = None\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Use dca to buy in etfs on a certain date\n",
    "\n",
    "        Args:\n",
    "            day:\n",
    "            etfs: tickers\n",
    "            shares (Optional): number of shares to buy of each etf\n",
    "            amt (Optional): dollars to invest each time. Only share or amt needs to be specified. If both are provided, share has a higher priority, and amt will be ignored\n",
    "            weights (Optional): It specifies the portfolio weights across ETFs. Sum to 1 \n",
    "\n",
    "        Returns:\n",
    "            a pd.Series that includes Date, etf shares to buy and Invest_Value\n",
    "        \"\"\"\n",
    "        day_df = self.hist_df.loc[(self.hist_df['Date'] == day) & (self.hist_df['Ticker'].isin(etfs))]\n",
    "        if shares is not None:\n",
    "            share_df = pd.DataFrame({'shares': shares, 'Ticker': etfs})\n",
    "            buy_df = share_df.merge(day_df, on='Ticker', how='inner')\n",
    "            buy_df['Value'] = buy_df['shares'] * buy_df['Open']\n",
    "            amt = buy_df['Value'].sum()\n",
    "        else:\n",
    "            amts = amt * np.array(weights)\n",
    "            amts_df = pd.DataFrame({\n",
    "                'Ticker': etfs,\n",
    "                'Value': amts\n",
    "            })\n",
    "            buy_df = amts_df.merge(day_df, on='Ticker', how='inner')\n",
    "            etfs = buy_df['Ticker'].values.tolist()\n",
    "            buy_df['shares'] = buy_df['Value'] / buy_df['Open']\n",
    "            shares = buy_df['shares'].values.tolist()\n",
    "        \n",
    "        s = pd.Series(\n",
    "            [day] + shares + [amt],\n",
    "            index=['Date'] + etfs + ['Invest_Value']\n",
    "        )\n",
    "        return s\n",
    "    \n",
    "    def __rebalance(\n",
    "        self, \n",
    "        day: date,\n",
    "        etfs: List[str],\n",
    "        weights: List[float],\n",
    "        invest_df: pd.DataFrame\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Perform rebalance at the date based on Open Price\n",
    "\n",
    "        Args:\n",
    "            day: which day to perform rebalance\n",
    "            etfs: tickers\n",
    "            weights: sum to 1\n",
    "            invest_df: a pd.DataFrame with Date, etfs and Invest_Value that lists the history of transactions\n",
    "\n",
    "        Returns:\n",
    "            a pd.Series that includes Date, etf shares to buy and Invest_Value. The ETF shares represent the changes in the holdings of all ETFs and the Invest_Value=0\n",
    "        \"\"\"\n",
    "        # calculate total shares of each etf\n",
    "        prior_shares = invest_df[etfs].sum()\n",
    "\n",
    "        # calculate total value of each etf\n",
    "        prior_values = self.__calculate_total_value(day, invest_df)\n",
    "\n",
    "        # calculate total portfolio value\n",
    "        prior_total_value = prior_values.sum()\n",
    "\n",
    "        # calculate the rebalanced value of each etf\n",
    "        after_values = prior_total_value * np.array(weights)\n",
    "\n",
    "        # get the day open price of each etf\n",
    "        prices = self.__get_day_price(day, etfs, 'Open')\n",
    "\n",
    "        # calculate the rebalancd shares of each etf\n",
    "        after_shares = after_values / np.array(prices)\n",
    "\n",
    "        # calculate share changes\n",
    "        s = after_shares - prior_shares\n",
    "        s['Date'] = day\n",
    "        s['Invest_Value'] = 0\n",
    "        return s\n",
    "\n",
    "    def dca_trade(\n",
    "        self,\n",
    "        etfs: List[str], \n",
    "        freq: str, \n",
    "        shares: Optional[List[int]] = [2], \n",
    "        amt: Optional[float] = 500, \n",
    "        trading_day: Optional[str] = 'MON', \n",
    "        rebalance_flag: bool = False, \n",
    "        weights: Optional[List[float]] = None, \n",
    "        start_dt: Optional[date] = None\n",
    "    ) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Calculate the annualized return and sharpe ratio of dollar cost average on a single etf\n",
    "        \n",
    "        Args:\n",
    "            etfs: tickers\n",
    "            freq: weekly/biweekly/monthly\n",
    "            shares (Optional): number of shares to buy of each etf\n",
    "            amt (Optional): dollars to invest each time. Only share or amt needs to be specified. If both are provided, share has a higher priority, and amt will be ignored\n",
    "            trading_day (Optional): MON/TUE/WED/THU/FRI/START/END\n",
    "            rebalance_flag: bool whether to perform a rebalance at the beginning of a year\n",
    "            weights (Optional): It specifies the portfolio weights across ETFs. Sum to 1 \n",
    "            start_dt (Optional): If not provided, will use the inception date\n",
    "\n",
    "        Returns:\n",
    "            annualized_return\n",
    "            sharpe_ratio\n",
    "        \"\"\"\n",
    "        invest_df = pd.DataFrame(columns=['Date'] + etfs + ['Invest_Value'])\n",
    "\n",
    "        # get trading days\n",
    "        trade_days = self.__get_trade_days(etfs, start_dt, freq, trading_day)\n",
    "        last_day_year = trade_days[0].year\n",
    "\n",
    "        # on each trade day\n",
    "        for day in trade_days:\n",
    "            day_year = day.year\n",
    "            # if a new year and rebalance_flag\n",
    "            if day_year > last_day_year and rebalance_flag:\n",
    "                # get the first day of a year and perform rebalance\n",
    "                first_business_day = self.hist_df.loc[self.hist_df['Date'] >= date(day_year, 1, 1), 'Date'].min()\n",
    "                invest_s = self.__rebalance(first_business_day, etfs, weights, invest_df)\n",
    "                invest_df = pd.concat([invest_df, pd.DataFrame([invest_s])], ignore_index=True)\n",
    "                last_day_year = day_year\n",
    "\n",
    "            # calculate shares to buy and total invest value\n",
    "            invest_s = self.__dca_buy(day, etfs, shares, amt, weights)\n",
    "            # append it to invest_df\n",
    "            invest_df = pd.concat([invest_df, pd.DataFrame([invest_s])], ignore_index=True)\n",
    "\n",
    "        # calculate return rate and sharpe ratio\n",
    "        annualized_return = self.__calculate_annualized_return(invest_df)\n",
    "        sharpe_ratio = self.__calculate_sharpe_ratio(invest_df)\n",
    "        return annualized_return, sharpe_ratio\n",
    "\n",
    "\n",
    "    def rule_trade(\n",
    "        self,\n",
    "        etfs: List[str], \n",
    "        shares: List[int], \n",
    "        thresholds: List[float], \n",
    "        rebalance_flag: bool = False, \n",
    "        weights: Optional[List[float]] = None,\n",
    "        start_dt: Optional[date] = None    \n",
    "    ) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Calculate annualized return and sharpe ratio of a certain trading strategy\n",
    "\n",
    "        Args:\n",
    "            etfs: tickers\n",
    "            shares (Optional): number of shares to buy of each etf\n",
    "            thresholds: a list of threshold. Only buy in certain shares if the price change is beyond the thresholds. \n",
    "            rebalance_flag: bool whether to perform a rebalance at the beginning of a year\n",
    "            weights (Optional): It specifies the portfolio weights across ETFs. Sum to 1 \n",
    "            start_dt (Optional): If not provided, will use the inception date\n",
    "\n",
    "        Returns:\n",
    "            annualized_return\n",
    "            sharpe_ratio\n",
    "        \"\"\"\n",
    "        # get all trade days\n",
    "        start_dt, end_dt = self.__get_trade_period(etfs, start_dt)\n",
    "        trade_days = pd.date_range(start_dt, end_dt, freq='B', inclusive='both').date\n",
    "        trade_days = np.intersect1d(trade_days, self.hist_df['Date'].values)\n",
    "\n",
    "        # get low and high percentage\n",
    "        etf_df = self.hist_df.loc[self.hist_df['Ticker'].isin(etfs)]\n",
    "        etf_df['Low_Pctg'] = etf_df['Low'] / etf_df['Open'] - 1\n",
    "        etf_df['High_Pctg'] = etf_df['High'] / etf_df['Open'] - 1\n",
    "        \n",
    "        invest_df = pd.DataFrame(columns=['Date'] + etfs + ['Invest_Value'])\n",
    "        last_day_year = trade_days[0].year\n",
    "        # for each day\n",
    "        for day in trade_days:\n",
    "            day_year = day.year\n",
    "            # if a new year and rebalance_flag\n",
    "            if day_year > last_day_year and rebalance_flag:\n",
    "                # get the first day of a year and perform rebalance\n",
    "                first_business_day = self.hist_df.loc[self.hist_df['Date'] >= date(day_year, 1, 1), 'Date'].min()\n",
    "                invest_s = self.__rebalance(first_business_day, etfs, weights, invest_df)\n",
    "                invest_df = pd.concat([invest_df, pd.DataFrame([invest_s])], ignore_index=True)\n",
    "                last_day_year = day_year\n",
    "\n",
    "            # invest_value = 0\n",
    "            invest_value = 0\n",
    "            # construct invest_s\n",
    "            invest_s = pd.Series([day], index=['Date'])\n",
    "            # for each etf\n",
    "            for etf, threshold, share in zip(etfs, thresholds, shares):\n",
    "                etf_s = etf_df.loc[(etf_df['Ticker'] == etf) & (etf_df['Date'] == day)].iloc[0]\n",
    "                # check if change >= threshold\n",
    "                trade_flag = False\n",
    "                if threshold > 0:\n",
    "                    trade_flag = (etf_s['High_Pctg'] >= threshold)\n",
    "                else:\n",
    "                    trade_flag = (etf_s['Low_Pctg'] <= threshold)\n",
    "                # if yes, get share and add invest_value, else 0\n",
    "                if trade_flag:\n",
    "                    unit_price = etf_s['Open'] * (1 + threshold)\n",
    "                    buy_value = unit_price * share\n",
    "                    invest_value += buy_value\n",
    "                else:\n",
    "                    share = 0\n",
    "                invest_s[etf] = share\n",
    "\n",
    "            # if invest_value > 0 add invest_s to invest_df\n",
    "            if invest_value > 0:\n",
    "                invest_s['Invest_Value'] = invest_value\n",
    "                invest_df = pd.concat([invest_df, pd.DataFrame([invest_s])], ignore_index=True)\n",
    "        \n",
    "        # calculate return rate and sharpe ratio\n",
    "        annualized_return = self.__calculate_annualized_return(invest_df)\n",
    "        sharpe_ratio = self.__calculate_sharpe_ratio(invest_df)\n",
    "        return annualized_return, sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e7fbb11-ad49-4ef7-b5a4-d2ba8db51ca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trade = Trade()\n",
    "display(trade.hist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "575aeaed-0d30-4502-947c-9c4c4453628c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### DCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab1456b-6dd3-4e28-b760-b2d33f8bb90e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "etfs_choices = [['VGT'], ['VOO'], ['SCHD'], ['VGT', 'VOO'], ['VGT', 'SCHD'], ['VOO', 'SCHD'], ['VGT', 'VOO', 'SCHD']]\n",
    "freq_choices = ['weekly', 'biweekly', 'monthly']\n",
    "share_dict = {\n",
    "    'VGT': 2,\n",
    "    'VOO': 2,\n",
    "    'SCHD': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87700f5d-80f8-4589-b3ba-805c0627aacb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ss = []\n",
    "for etfs in etfs_choices:\n",
    "    shares = [share_dict[etf] for etf in etfs]\n",
    "    for freq in freq_choices:\n",
    "        # config trading_day\n",
    "        if freq == 'weekly':\n",
    "            trading_day_choices = ['MON', 'TUE', 'WED', 'THU', 'FRI']\n",
    "        else:\n",
    "            trading_day_choices = ['START', 'END']\n",
    "        for trading_day in trading_day_choices:\n",
    "            if len(etfs) > 1:\n",
    "                rebalance_flag_choices = [True, False]\n",
    "            else:\n",
    "                rebalance_flag_choices = [False]\n",
    "            for rebalance_flag in rebalance_flag_choices:\n",
    "                if rebalance_flag:\n",
    "                    if len(etfs) == 2:\n",
    "                        weights_choices = [[0.5, 0.5], [0.6, 0.4], [0.7, 0.3], [0.75, 0.25], [0.8, 0.2]]\n",
    "                    else:\n",
    "                        weights_choices = [[0.4, 0.4, 0.2], [0.4, 0.3, 0.3], [0.5, 0.25, 0.25], [0.6, 0.2, 0.2], [0.8, 0.1, 0.1]]\n",
    "                else:\n",
    "                    weights_choices = [None]\n",
    "                for weights in weights_choices:\n",
    "                    annualized_return, sharpe_ratio = trade.dca_trade(\n",
    "                        etfs=etfs,\n",
    "                        freq=freq,\n",
    "                        shares=shares,\n",
    "                        trading_day=trading_day,\n",
    "                        rebalance_flag=rebalance_flag,\n",
    "                        weights=weights\n",
    "                    )\n",
    "                    s = pd.Series(\n",
    "                        data=[str(etfs), freq, str(shares), trading_day, rebalance_flag, str(weights), annualized_return, sharpe_ratio],\n",
    "                        index=['etfs', 'freq', 'shares', 'trading_day', 'rebalance_flag', 'weights', 'annualized_return', 'sharpe_ratio']\n",
    "                    )\n",
    "                    ss.append(s)\n",
    "dca_share_df = pd.DataFrame(ss)\n",
    "display(dca_share_df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3218105e-f827-4239-9050-7ed6aeb95450",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ss = []\n",
    "for etfs in etfs_choices:\n",
    "    amt = 1000\n",
    "    for freq in freq_choices:\n",
    "        # config trading_day\n",
    "        if freq == 'weekly':\n",
    "            trading_day_choices = ['MON', 'TUE', 'WED', 'THU', 'FRI']\n",
    "        else:\n",
    "            trading_day_choices = ['START', 'END']\n",
    "        for trading_day in trading_day_choices:\n",
    "            if len(etfs) > 1:\n",
    "                rebalance_flag_choices = [True, False]\n",
    "            else:\n",
    "                rebalance_flag_choices = [False]\n",
    "            for rebalance_flag in rebalance_flag_choices:\n",
    "                if len(etfs) == 1:\n",
    "                    weights_choices = [[1]]\n",
    "                elif len(etfs) == 2:\n",
    "                    weights_choices = [[0.5, 0.5], [0.6, 0.4], [0.7, 0.3], [0.75, 0.25], [0.8, 0.2]]\n",
    "                else:\n",
    "                    weights_choices = [[0.4, 0.4, 0.2], [0.4, 0.3, 0.3], [0.5, 0.25, 0.25], [0.6, 0.2, 0.2], [0.8, 0.1, 0.1]]\n",
    "                for weights in weights_choices:\n",
    "                    shares = None\n",
    "                    annualized_return, sharpe_ratio = trade.dca_trade(\n",
    "                        etfs=etfs,\n",
    "                        freq=freq,\n",
    "                        shares=shares,\n",
    "                        amt=amt,\n",
    "                        trading_day=trading_day,\n",
    "                        rebalance_flag=rebalance_flag,\n",
    "                        weights=weights\n",
    "                    )\n",
    "                    s = pd.Series(\n",
    "                        data=[str(etfs), freq, str(shares), trading_day, rebalance_flag, str(weights), annualized_return, sharpe_ratio],\n",
    "                        index=['etfs', 'freq', 'shares', 'trading_day', 'rebalance_flag', 'weights', 'annualized_return', 'sharpe_ratio']\n",
    "                    )\n",
    "                    ss.append(s)\n",
    "dca_amt_df = pd.DataFrame(ss)\n",
    "display(dca_amt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47100bc9-c53c-4271-a6a0-041a10c69009",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84ce626c-1d59-4a4f-be34-b147506e84d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "share_dict = {\n",
    "    'VGT': 2,\n",
    "    'VOO': 2,\n",
    "    'SCHD': 10\n",
    "}\n",
    "ss = []\n",
    "for etfs in etfs_choices:\n",
    "    shares = [share_dict[etf] for etf in etfs]\n",
    "    threshold_cand = [-0.02, -0.015, -0.01, -0.005, 0.005, 0.01, 0.015, 0.02]\n",
    "    for thresholds in itertools.product(*([threshold_cand]*len(etfs))):\n",
    "        if len(etfs) > 1:\n",
    "            rebalance_flag_choices = [True, False]\n",
    "        else:\n",
    "            rebalance_flag_choices = [False]\n",
    "        for rebalance_flag in rebalance_flag_choices:\n",
    "            if len(etfs) == 1:\n",
    "                weights_choices = [[1]]\n",
    "            elif len(etfs) == 2:\n",
    "                weights_choices = [[0.5, 0.5], [0.6, 0.4], [0.7, 0.3], [0.75, 0.25], [0.8, 0.2]]\n",
    "            else:\n",
    "                weights_choices = [[0.4, 0.4, 0.2], [0.4, 0.3, 0.3], [0.5, 0.25, 0.25], [0.6, 0.2, 0.2], [0.8, 0.1, 0.1]]\n",
    "            for weights in weights_choices:\n",
    "                annualized_return, sharpe_ratio = trade.rule_trade(\n",
    "                    etfs=etfs,\n",
    "                    shares=shares,\n",
    "                    thresholds=thresholds,\n",
    "                    rebalance_flag=rebalance_flag,\n",
    "                    weights=weights\n",
    "                )\n",
    "                s = pd.Series(\n",
    "                        data=[str(etfs), str(thresholds), str(shares), rebalance_flag, str(weights), annualized_return, sharpe_ratio],\n",
    "                        index=['etfs', 'thresholds', 'shares', 'rebalance_flag', 'weights', 'annualized_return', 'sharpe_ratio']\n",
    "                )\n",
    "                print(s)\n",
    "                ss.append(s)\n",
    "rule_df = pd.DataFrame(ss)\n",
    "display(rule_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "647ab037-9699-46be-8bef-a474ebf0f505",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([dca_share_df, dca_amt_df, rule_df], ignore_index=True)\n",
    "df = df.sort_values(by=['sharpe_ratio', 'annualized_return'], ascending=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab14ae7a-cf16-4416-b036-9480a45fc0ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Finance",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
