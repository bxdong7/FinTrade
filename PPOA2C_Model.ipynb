{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgNLzLghprs2",
        "outputId": "3747caf1-cc06-4a9b-9128-fbe8705a27a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (1.24.3)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (4.3.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (0.0.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stable_baselines3 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.0.0)\n",
            "Requirement already satisfied: gymnasium==0.28.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines3) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines3) (1.24.3)\n",
            "Requirement already satisfied: torch>=1.11 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines3) (1.12.1)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines3) (1.4.3)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines3) (3.5.2)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium==0.28.1->stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium==0.28.1->stable_baselines3) (4.3.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium==0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines3) (4.34.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines3) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines3) (21.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines3) (9.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->stable_baselines3) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stable_baselines in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.10.2)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines) (0.26.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines) (1.8.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines) (1.3.1)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines) (2.2.1)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines) (4.8.0.74)\n",
            "Requirement already satisfied: numpy in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines) (1.24.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines) (1.4.3)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stable_baselines) (3.5.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (0.0.8)\n",
            "Requirement already satisfied: ale-py~=0.8.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (0.8.1)\n",
            "Requirement already satisfied: pygame==2.1.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (2.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines) (4.34.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines) (21.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines) (9.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->stable_baselines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->stable_baselines) (2022.1)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ale-py~=0.8.0->gym[atari,classic_control]>=0.11->stable_baselines) (6.0.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ale-py~=0.8.0->gym[atari,classic_control]>=0.11->stable_baselines) (4.3.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install gymnasium\n",
        "%pip install stable_baselines3\n",
        "%pip install stable_baselines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.13.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.2.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (1.11.1)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (0.10.0)\n",
            "Requirement already satisfied: colorlog in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (1.4.49)\n",
            "Requirement already satisfied: tqdm in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from alembic>=1.5.0->optuna) (4.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from colorlog->optuna) (0.4.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install keras\n",
        "%pip install optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (23.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\12016\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GwItbhKptYL",
        "outputId": "d807f457-2636-4100-aeda-155e5a6382c5"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO, A2C\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import numpy as np\n",
        "from gym_anytrading.envs import StocksEnv\n",
        "import gym_anytrading\n",
        "import quantstats as qs\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import optuna\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "logger = logging.getLogger('training')\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "file_handler = logging.FileHandler('training.log')\n",
        "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
        "file_handler.setFormatter(formatter)\n",
        "logger.addHandler(file_handler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_KR3I7wxkn5",
        "outputId": "5cb82a32-7957-410b-f66c-993985e624f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "vgt_data = yf.download(\"VGT\", period = '5y')\n",
        "voo_data = yf.download(\"VOO\", period = '5y')\n",
        "spy_data = yf.download('SPY', period = '5y')\n",
        "data = pd.concat([vgt_data, voo_data]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#SIMPLE 80:20 SPLIT\n",
        "\n",
        "split_index = int(len(data) * 0.8)\n",
        "train_df = data[:split_index]\n",
        "val_df = data[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Rolling window split. Two year training data\n",
        "\n",
        "train_df = data[:2*365]\n",
        "val_df_1 = data[2*365:3*365]\n",
        "val_df_2 = data[3*365:4*365]\n",
        "val_df_3 = data[4*365:5*365]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ModelCreation():\n",
        "\n",
        "    #Creating Logging env\n",
        "    logger = logging.getLogger('training')\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    file_handler = logging.FileHandler('training.log')\n",
        "    formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
        "    file_handler.setFormatter(formatter)\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    #Creating training env\n",
        "\n",
        "    window_size = 10\n",
        "    start_index = window_size\n",
        "    end_index = len(data)\n",
        "\n",
        "    train_env = gym.make(\n",
        "            'stocks-v0',\n",
        "            df = train_df,\n",
        "            window_size = window_size,\n",
        "            frame_bound = (start_index, end_index)\n",
        "        )\n",
        "\n",
        "    val_env1 = gym.make(\n",
        "        'stocks-v0',\n",
        "        df = val_df_1,\n",
        "        window_size = window_size,\n",
        "        frame_bound = (start_index, end_index)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    val_env2 = gym.make(\n",
        "        'stocks-v0',\n",
        "        df = val_df_2,\n",
        "        window_size = window_size,\n",
        "        frame_bound = (start_index, end_index)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    val_env3 = gym.make(\n",
        "        'stocks-v0',\n",
        "        df = val_df_3,\n",
        "        window_size = window_size,\n",
        "        frame_bound = (start_index, end_index)\n",
        "    )\n",
        "\n",
        "    env1 = DummyVecEnv([lambda : train_env, lambda : val_env1, lambda : val_env2, lambda : val_env3])\n",
        "\n",
        "    #Setting up hyperparameter tuners\n",
        "\n",
        "    def optimizePPO(trial):\n",
        "        return {\n",
        "            'n_steps' : int(trial.suggest_loguniform('n_steps', 16, 2048)),\n",
        "            'gamma' : trial.suggest_loguniform('gamma', 0.9, 0.9999),\n",
        "            'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-5, 1.),\n",
        "            'ent_coef' : trial.suggest_loguniform('ent_coef', 1e-8, 1e-1),\n",
        "            'clip_range': trial.suggest_uniform('cliprange', 0.1, 0.4),\n",
        "            'n_epochs' : int(trial.suggest_loguniform('noptepochs', 1, 48)),\n",
        "            'gae_lambda': trial.suggest_uniform('lam', 0.8, 1.)\n",
        "        }\n",
        "\n",
        "    def OptimizeA2C(trial):\n",
        "\n",
        "        return {\n",
        "            'n_steps': trial.suggest_int('n_steps', 16, 2048),\n",
        "            'gamma': trial.suggest_uniform('gamma', 0.9, 0.9999),\n",
        "            'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.),\n",
        "            'ent_coef': trial.suggest_loguniform('entropy_coef', 1e-8, 1e-1),\n",
        "            'vf_coef': trial.suggest_loguniform('value_loss_coef', 0.5, 1.) \n",
        "        }\n",
        "\n",
        "    file_handler.close()\n",
        "    logger.removeHandler(file_handler)\n",
        "\n",
        "    file_handler = logging.FileHandler('training.log')\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "\n",
        "    logger.info('Starting Hyperparameter Tuning...')\n",
        "\n",
        "    def Optimize_PPO_agent(trial):\n",
        "        model_params = optimizePPO(trial)\n",
        "        env = env1\n",
        "        model = PPO('MlpPolicy', train_env, verbose=1, **model_params)\n",
        "        model.learn(10000)\n",
        "\n",
        "        rewards = []\n",
        "        global n_steps\n",
        "\n",
        "        n_episodes, reward_sum = 0, 0.0\n",
        "\n",
        "        obs = env.reset()\n",
        "        while n_episodes < 4:\n",
        "            action, _ = model.predict(obs)\n",
        "            obs, reward, done, _ = env.step(action)\n",
        "            reward_sum += reward\n",
        "\n",
        "            if done.all():\n",
        "                rewards.append(reward_sum)\n",
        "                reward_sum = 0.0\n",
        "                n_episodes += 1\n",
        "                obs = env.reset()\n",
        "\n",
        "        last_reward = np.mean(rewards)\n",
        "        trial.report(-1 * last_reward, step = n_steps)\n",
        "\n",
        "        return -1 * last_reward\n",
        "\n",
        "    def Optimize_A2C_agent(trial):\n",
        "        model_params = OptimizeA2C(trial)\n",
        "        env = env1\n",
        "        model = A2C('MlpPolicy', train_env, verbose=1, **model_params)\n",
        "        model.learn(10000)\n",
        "\n",
        "        rewards = []\n",
        "        global n_steps\n",
        "\n",
        "        n_episodes, reward_sum = 0, 0.0\n",
        "\n",
        "        obs = env.reset()\n",
        "        while n_episodes < 4:\n",
        "            action, _ = model.predict(obs)\n",
        "            obs, reward, done, _ = env.step(action)\n",
        "            reward_sum += reward\n",
        "\n",
        "            if done.all():\n",
        "                rewards.append(reward_sum)\n",
        "                reward_sum = 0.0\n",
        "                n_episodes += 1\n",
        "                obs = env.reset()\n",
        "\n",
        "        last_reward = np.mean(rewards)\n",
        "        trial.report(-1 * last_reward, step = n_steps)\n",
        "\n",
        "        return -1 * last_reward\n",
        "\n",
        "\n",
        "    ppo_study = optuna.create_study()\n",
        "    ppo_study.optimize(Optimize_PPO_agent, n_trials = 1)\n",
        "\n",
        "    a2c_study = optuna.create_study()\n",
        "    a2c_study.optimize(Optimize_A2C_agent, n_trials = 1)\n",
        "\n",
        "    ppo_best_params = ppo_study.best_params\n",
        "    a2c_best_params = a2c_study.best_params\n",
        "\n",
        "    logger.info(f'Hyperparameter tuning is complete. The A2C best parameters are: {a2c_best_params} and the best PPO parameters are: {ppo_best_params}')\n",
        "\n",
        "    logger.info('Initializing the PPO and A2C models...')\n",
        "    ppo_agent = PPO('MlpPolicy', train_env, verbose=1, )\n",
        "    a2c_agent = A2C('MlpPolicy', train_env, verbose=1, )\n",
        "\n",
        "    logger.info('Training the PPO Agent...')\n",
        "    ppo_agent.learn(total_timesteps=1000)\n",
        "\n",
        "    logger.info('Training the A2C Agent...')\n",
        "    a2c_agent.learn(total_timesteps=1000)\n",
        "\n",
        "    logger.info('Training is complete')\n",
        "\n",
        "    envs = [val_env1, val_env2, val_env3]\n",
        "\n",
        "    def evalModel():\n",
        "\n",
        "        num_years = 3\n",
        "        counter = 3\n",
        "\n",
        "        while counter <= num_years:\n",
        "\n",
        "            for i in envs:\n",
        "                ppo_rewards = []\n",
        "                obs1 = i.reset()\n",
        "\n",
        "                while True:\n",
        "                    action, _ = ppo_agent.predict(obs1)\n",
        "                    logger.info(f'PPO Took action {action} in state {obs1}')\n",
        "                    obs, reward, done, info = i.step(action)\n",
        "                    ppo_rewards.append(reward)\n",
        "\n",
        "                    if done:\n",
        "                        break\n",
        "\n",
        "                print(f'PPO average validation for year {counter} reward: ', np.mean(ppo_rewards))\n",
        "\n",
        "\n",
        "                a2c_rewards = []\n",
        "                obs2 = val_env1.reset()\n",
        "\n",
        "                while True:\n",
        "                    action, _ = a2c_agent.predict(obs2)\n",
        "                    obs, reward, done, info = val_env1.step(action)\n",
        "                    a2c_rewards.append(reward)\n",
        "\n",
        "                    if done:\n",
        "                        break\n",
        "\n",
        "                print(f'A2C average validation for year {counter} reward: ', np.mean(a2c_rewards))\n",
        "\n",
        "                if np.mean(ppo_rewards) > np.mean(a2c_rewards):\n",
        "                    agent = ppo_agent\n",
        "                    action, _ = agent.predict(obs1)\n",
        "                    print(f'Agent chosen for year {counter} is PPO')\n",
        "                else:\n",
        "                    agent = a2c_agent\n",
        "                    action, _ = agent.predict(obs2)\n",
        "                    print(f'Agent chosen for year {counter} is A2C')\n",
        "\n",
        "                counter += 1\n",
        "            \n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        print(\"info:\", info)\n",
        "        plt.plot(ppo_rewards, label = 'PPO')\n",
        "        #plt.plot(a2c_rewards, label = 'A2C')\n",
        "\n",
        "        plt.legend()\n",
        "        plt.title('Agent Rewards')\n",
        "        plt.show()\n",
        "    evalModel()\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-01 16:12:58,596] A new study created in memory with name: no-name-6568b2aa-7a47-4e12-a7c3-f20bd19d7d4f\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'n_steps' : int(trial.suggest_loguniform('n_steps', 16, 2048)),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:58: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma' : trial.suggest_loguniform('gamma', 0.9, 0.9999),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:59: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-5, 1.),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:60: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'ent_coef' : trial.suggest_loguniform('ent_coef', 1e-8, 1e-1),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:61: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'clip_range': trial.suggest_uniform('cliprange', 0.1, 0.4),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:62: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'n_epochs' : int(trial.suggest_loguniform('noptepochs', 1, 48)),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:63: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'gae_lambda': trial.suggest_uniform('lam', 0.8, 1.)\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\ppo\\ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 792`, after every 12 untruncated mini-batches, there will be a truncated mini-batch of size 24\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=792 and n_envs=1)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 719      |\n",
            "|    ep_rew_mean     | 12       |\n",
            "| time/              |          |\n",
            "|    fps             | 2037     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 0        |\n",
            "|    total_timesteps | 792      |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 49.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 897         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 1584        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015794264 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.33        |\n",
            "|    entropy_loss         | -0.671      |\n",
            "|    explained_variance   | 0.00595     |\n",
            "|    learning_rate        | 0.0031      |\n",
            "|    loss                 | 3.71        |\n",
            "|    n_updates            | 18          |\n",
            "|    policy_gradient_loss | 0.00238     |\n",
            "|    value_loss           | 22.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 75.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 746         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 2376        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024985453 |\n",
            "|    clip_fraction        | 0.0675      |\n",
            "|    clip_range           | 0.33        |\n",
            "|    entropy_loss         | -0.63       |\n",
            "|    explained_variance   | -0.00107    |\n",
            "|    learning_rate        | 0.0031      |\n",
            "|    loss                 | 14.2        |\n",
            "|    n_updates            | 36          |\n",
            "|    policy_gradient_loss | 0.0014      |\n",
            "|    value_loss           | 18.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 87.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 707         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 3168        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008027377 |\n",
            "|    clip_fraction        | 0.0892      |\n",
            "|    clip_range           | 0.33        |\n",
            "|    entropy_loss         | -0.585      |\n",
            "|    explained_variance   | -3.29e-05   |\n",
            "|    learning_rate        | 0.0031      |\n",
            "|    loss                 | 15.7        |\n",
            "|    n_updates            | 54          |\n",
            "|    policy_gradient_loss | -0.0012     |\n",
            "|    value_loss           | 22.6        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 107          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 687          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 3960         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044533866 |\n",
            "|    clip_fraction        | 0.0384       |\n",
            "|    clip_range           | 0.33         |\n",
            "|    entropy_loss         | -0.643       |\n",
            "|    explained_variance   | -1.76e-05    |\n",
            "|    learning_rate        | 0.0031       |\n",
            "|    loss                 | 5.18         |\n",
            "|    n_updates            | 72           |\n",
            "|    policy_gradient_loss | 0.00234      |\n",
            "|    value_loss           | 22.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 103          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 688          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 4752         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067978436 |\n",
            "|    clip_fraction        | 0.0751       |\n",
            "|    clip_range           | 0.33         |\n",
            "|    entropy_loss         | -0.683       |\n",
            "|    explained_variance   | 8.34e-07     |\n",
            "|    learning_rate        | 0.0031       |\n",
            "|    loss                 | 16.9         |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00389     |\n",
            "|    value_loss           | 25.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 116          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 690          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 5544         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036813654 |\n",
            "|    clip_fraction        | 0.0273       |\n",
            "|    clip_range           | 0.33         |\n",
            "|    entropy_loss         | -0.667       |\n",
            "|    explained_variance   | 5.54e-06     |\n",
            "|    learning_rate        | 0.0031       |\n",
            "|    loss                 | 13.6         |\n",
            "|    n_updates            | 108          |\n",
            "|    policy_gradient_loss | 0.000256     |\n",
            "|    value_loss           | 33.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 107         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 688         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 6336        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017771004 |\n",
            "|    clip_fraction        | 0.0834      |\n",
            "|    clip_range           | 0.33        |\n",
            "|    entropy_loss         | -0.674      |\n",
            "|    explained_variance   | 4.12e-05    |\n",
            "|    learning_rate        | 0.0031      |\n",
            "|    loss                 | 10.9        |\n",
            "|    n_updates            | 126         |\n",
            "|    policy_gradient_loss | 0.0051      |\n",
            "|    value_loss           | 18.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 105         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 691         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 7128        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.036294553 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.33        |\n",
            "|    entropy_loss         | -0.664      |\n",
            "|    explained_variance   | 9.78e-06    |\n",
            "|    learning_rate        | 0.0031      |\n",
            "|    loss                 | 4.33        |\n",
            "|    n_updates            | 144         |\n",
            "|    policy_gradient_loss | 0.00678     |\n",
            "|    value_loss           | 26.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 94.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 692          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 7920         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032680407 |\n",
            "|    clip_fraction        | 0.0829       |\n",
            "|    clip_range           | 0.33         |\n",
            "|    entropy_loss         | -0.633       |\n",
            "|    explained_variance   | -7.27e-06    |\n",
            "|    learning_rate        | 0.0031       |\n",
            "|    loss                 | 29.8         |\n",
            "|    n_updates            | 162          |\n",
            "|    policy_gradient_loss | 0.00304      |\n",
            "|    value_loss           | 27.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 101         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 692         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 8712        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010140818 |\n",
            "|    clip_fraction        | 0.091       |\n",
            "|    clip_range           | 0.33        |\n",
            "|    entropy_loss         | -0.628      |\n",
            "|    explained_variance   | -5.84e-05   |\n",
            "|    learning_rate        | 0.0031      |\n",
            "|    loss                 | 21.9        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | 0.00357     |\n",
            "|    value_loss           | 27.1        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 719        |\n",
            "|    ep_rew_mean          | 103        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 694        |\n",
            "|    iterations           | 12         |\n",
            "|    time_elapsed         | 13         |\n",
            "|    total_timesteps      | 9504       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03603609 |\n",
            "|    clip_fraction        | 0.12       |\n",
            "|    clip_range           | 0.33       |\n",
            "|    entropy_loss         | -0.664     |\n",
            "|    explained_variance   | -5.6e-05   |\n",
            "|    learning_rate        | 0.0031     |\n",
            "|    loss                 | 7.37       |\n",
            "|    n_updates            | 198        |\n",
            "|    policy_gradient_loss | 0.00285    |\n",
            "|    value_loss           | 19.1       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 101          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 695          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 10296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010237085 |\n",
            "|    clip_fraction        | 0.0665       |\n",
            "|    clip_range           | 0.33         |\n",
            "|    entropy_loss         | -0.631       |\n",
            "|    explained_variance   | 7.15e-06     |\n",
            "|    learning_rate        | 0.0031       |\n",
            "|    loss                 | 8.11         |\n",
            "|    n_updates            | 216          |\n",
            "|    policy_gradient_loss | -0.00265     |\n",
            "|    value_loss           | 19.2         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-01 16:20:06,092] Trial 0 finished with value: -983.365234375 and parameters: {'n_steps': 792.1375974758399, 'gamma': 0.9054993289278659, 'learning_rate': 0.0031041497989099933, 'ent_coef': 3.29584164456723e-08, 'cliprange': 0.32973015504976755, 'noptepochs': 18.56636834566542, 'lam': 0.8290040564843704}. Best is trial 0 with value: -983.365234375.\n",
            "[I 2023-08-01 16:20:06,093] A new study created in memory with name: no-name-730e0f75-56b8-41f2-aea0-c2d71d259ce3\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:70: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'gamma': trial.suggest_uniform('gamma', 0.9, 0.9999),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'ent_coef': trial.suggest_loguniform('entropy_coef', 1e-8, 1e-1),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_20532\\2103417826.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'vf_coef': trial.suggest_loguniform('value_loss_coef', 0.5, 1.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-01 16:26:58,559] Trial 0 finished with value: -1321.1689453125 and parameters: {'n_steps': 1413, 'gamma': 0.9138864177041485, 'learning_rate': 1.3121721092174787e-05, 'entropy_coef': 0.010056158256219477, 'value_loss_coef': 0.765887510705601}. Best is trial 0 with value: -1321.1689453125.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 719      |\n",
            "|    ep_rew_mean     | 19.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 2008     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 1034     |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0935  |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.000132 |\n",
            "|    value_loss         | 5.88e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 719      |\n",
            "|    ep_rew_mean        | -44      |\n",
            "| time/                 |          |\n",
            "|    fps                | 1043     |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.114   |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 0.377    |\n",
            "|    value_loss         | 0.197    |\n",
            "------------------------------------\n",
            "PPO average validation for year 3 reward:  0.14197699767721575\n",
            "A2C average validation for year 3 reward:  0.07556505795926025\n",
            "Agent chosen for year 3 is PPO\n",
            "PPO average validation for year 4 reward:  0.12622897907838984\n",
            "A2C average validation for year 4 reward:  0.0394632802844721\n",
            "Agent chosen for year 4 is PPO\n",
            "PPO average validation for year 5 reward:  0.1379660482460496\n",
            "A2C average validation for year 5 reward:  0.0027966687908280367\n",
            "Agent chosen for year 5 is PPO\n",
            "info: {'total_reward': 0.990020751953125, 'total_profit': 0.8712431652448427, 'position': 0}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ModelCreation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gym\\utils\\passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (10, 2)\u001b[0m\n",
            "  logger.warn(\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "window_size = 10\n",
        "start_index = window_size\n",
        "end_index = len(data)\n",
        "\n",
        "train_env = gym.make(\n",
        "        'stocks-v0',\n",
        "        df = train_df,\n",
        "        window_size = window_size,\n",
        "        frame_bound = (start_index, end_index)\n",
        "    )\n",
        "\n",
        "val_env1 = gym.make(\n",
        "    'stocks-v0',\n",
        "    df = val_df_1,\n",
        "    window_size = window_size,\n",
        "    frame_bound = (start_index, end_index)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "val_env2 = gym.make(\n",
        "    'stocks-v0',\n",
        "    df = val_df_2,\n",
        "    window_size = window_size,\n",
        "    frame_bound = (start_index, end_index)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "val_env3 = gym.make(\n",
        "    'stocks-v0',\n",
        "    df = val_df_3,\n",
        "    window_size = window_size,\n",
        "    frame_bound = (start_index, end_index)\n",
        ")\n",
        "\n",
        "env1 = DummyVecEnv([lambda : train_env, lambda : val_env1, lambda : val_env2, lambda : val_env3])\n",
        "\n",
        "\n",
        "n_cpu = 4\n",
        "\n",
        "def optimizePPO(trial):\n",
        "    return {\n",
        "        'n_steps' : int(trial.suggest_loguniform('n_steps', 16, 2048)),\n",
        "        'gamma' : trial.suggest_loguniform('gamma', 0.9, 0.9999),\n",
        "        'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-5, 1.),\n",
        "        'ent_coef' : trial.suggest_loguniform('ent_coef', 1e-8, 1e-1),\n",
        "        'clip_range': trial.suggest_uniform('cliprange', 0.1, 0.4),\n",
        "        'n_epochs' : int(trial.suggest_loguniform('noptepochs', 1, 48)),\n",
        "        'gae_lambda': trial.suggest_uniform('lam', 0.8, 1.)\n",
        "    }\n",
        "\n",
        "def OptimizeA2C(trial):\n",
        "\n",
        "  return {\n",
        "    'n_steps': trial.suggest_int('n_steps', 16, 2048),\n",
        "    'gamma': trial.suggest_uniform('gamma', 0.9, 0.9999),\n",
        "    'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1.),\n",
        "    'entropy_coef': trial.suggest_loguniform('entropy_coef', 1e-8, 1e-1),\n",
        "    'value_loss_coef': trial.suggest_loguniform('value_loss_coef', 0.5, 1.) \n",
        "  }\n",
        "\n",
        "n_steps = 0\n",
        "\n",
        "def Optimize_PPO_agent(trial):\n",
        "    model_params = optimizePPO(trial)\n",
        "    env = env1\n",
        "    model = PPO('MlpPolicy', train_env, verbose=1, **model_params)\n",
        "    model.learn(10000)\n",
        "\n",
        "    rewards = []\n",
        "    global n_steps\n",
        "\n",
        "    n_episodes, reward_sum = 0, 0.0\n",
        "\n",
        "    obs = env.reset()\n",
        "    while n_episodes < 4:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        reward_sum += reward\n",
        "\n",
        "        if done.all():\n",
        "            rewards.append(reward_sum)\n",
        "            reward_sum = 0.0\n",
        "            n_episodes += 1\n",
        "            obs = env.reset()\n",
        "\n",
        "    last_reward = np.mean(rewards)\n",
        "    trial.report(-1 * last_reward, step = n_steps)\n",
        "\n",
        "    return -1 * last_reward\n",
        "\n",
        "\n",
        "def Optimize_A2C_agent(trial):\n",
        "    model_params = OptimizeA2C(trial)\n",
        "    env = env1\n",
        "    model = A2C('MlpPolicy', train_env, verbose=1, **model_params)\n",
        "    model.learn(10000)\n",
        "\n",
        "    rewards = []\n",
        "    global n_steps\n",
        "\n",
        "    n_episodes, reward_sum = 0, 0.0\n",
        "\n",
        "    obs = env.reset()\n",
        "    while n_episodes < 4:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        reward_sum += reward\n",
        "\n",
        "        if done.all():\n",
        "            rewards.append(reward_sum)\n",
        "            reward_sum = 0.0\n",
        "            n_episodes += 1\n",
        "            obs = env.reset()\n",
        "\n",
        "    last_reward = np.mean(rewards)\n",
        "    trial.report(-1 * last_reward, step = n_steps)\n",
        "\n",
        "    return -1 * last_reward\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-01 14:48:29,533] A new study created in memory with name: no-name-398a9f8a-a69a-45a5-bd86-7668e4da350c\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_13956\\918136109.py:45: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'n_steps' : int(trial.suggest_loguniform('n_steps', 16, 2048)),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_13956\\918136109.py:46: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma' : trial.suggest_loguniform('gamma', 0.9, 0.9999),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_13956\\918136109.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-5, 1.),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_13956\\918136109.py:48: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'ent_coef' : trial.suggest_loguniform('ent_coef', 1e-8, 1e-1),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_13956\\918136109.py:49: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'clip_range': trial.suggest_uniform('cliprange', 0.1, 0.4),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_13956\\918136109.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'n_epochs' : int(trial.suggest_loguniform('noptepochs', 1, 48)),\n",
            "C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_13956\\918136109.py:51: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'gae_lambda': trial.suggest_uniform('lam', 0.8, 1.)\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\ppo\\ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 451`, after every 7 untruncated mini-batches, there will be a truncated mini-batch of size 3\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=451 and n_envs=1)\n",
            "  warnings.warn(\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
            "  logger.warn(\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1699 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 0    |\n",
            "|    total_timesteps | 451  |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 114         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1329        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 0           |\n",
            "|    total_timesteps      | 902         |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026152235 |\n",
            "|    clip_fraction        | 0.0519      |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.679      |\n",
            "|    explained_variance   | 0.0032      |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 2.04        |\n",
            "|    n_updates            | 7           |\n",
            "|    policy_gradient_loss | -0.00644    |\n",
            "|    value_loss           | 59.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 114         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1303        |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 1353        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009650438 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.667      |\n",
            "|    explained_variance   | -0.00264    |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 25.1        |\n",
            "|    n_updates            | 14          |\n",
            "|    policy_gradient_loss | 0.000748    |\n",
            "|    value_loss           | 41.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 59.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1282        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 1804        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009790214 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.684      |\n",
            "|    explained_variance   | 0.00717     |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 24.4        |\n",
            "|    n_updates            | 21          |\n",
            "|    policy_gradient_loss | -0.00427    |\n",
            "|    value_loss           | 65.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 75.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1277        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 2255        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013258206 |\n",
            "|    clip_fraction        | 0.0332      |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.617      |\n",
            "|    explained_variance   | 0.00597     |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 11.1        |\n",
            "|    n_updates            | 28          |\n",
            "|    policy_gradient_loss | -0.00188    |\n",
            "|    value_loss           | 36.6        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 75.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1274         |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 2706         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021461623 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.244        |\n",
            "|    entropy_loss         | -0.627       |\n",
            "|    explained_variance   | 0.00697      |\n",
            "|    learning_rate        | 0.000444     |\n",
            "|    loss                 | 28.4         |\n",
            "|    n_updates            | 35           |\n",
            "|    policy_gradient_loss | -0.000359    |\n",
            "|    value_loss           | 93.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 76.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1273        |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 2           |\n",
            "|    total_timesteps      | 3157        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002780882 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.628      |\n",
            "|    explained_variance   | 0.0199      |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 1.42        |\n",
            "|    n_updates            | 42          |\n",
            "|    policy_gradient_loss | -0.00138    |\n",
            "|    value_loss           | 68.6        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 93.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1271         |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 3608         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 3.744823e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.244        |\n",
            "|    entropy_loss         | -0.611       |\n",
            "|    explained_variance   | 0.0186       |\n",
            "|    learning_rate        | 0.000444     |\n",
            "|    loss                 | 49.7         |\n",
            "|    n_updates            | 49           |\n",
            "|    policy_gradient_loss | 0.000299     |\n",
            "|    value_loss           | 37.5         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 719           |\n",
            "|    ep_rew_mean          | 93.6          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1266          |\n",
            "|    iterations           | 9             |\n",
            "|    time_elapsed         | 3             |\n",
            "|    total_timesteps      | 4059          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00096699427 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.244         |\n",
            "|    entropy_loss         | -0.613        |\n",
            "|    explained_variance   | 0.0173        |\n",
            "|    learning_rate        | 0.000444      |\n",
            "|    loss                 | 23.4          |\n",
            "|    n_updates            | 56            |\n",
            "|    policy_gradient_loss | 0.00052       |\n",
            "|    value_loss           | 118           |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 115         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1259        |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 4510        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012670565 |\n",
            "|    clip_fraction        | 0.0568      |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.659      |\n",
            "|    explained_variance   | 0.00713     |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 3.65        |\n",
            "|    n_updates            | 63          |\n",
            "|    policy_gradient_loss | -0.000362   |\n",
            "|    value_loss           | 46.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 115         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1255        |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 4961        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009195685 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.66       |\n",
            "|    explained_variance   | 0.0137      |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 10.8        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00635    |\n",
            "|    value_loss           | 57.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 112         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1254        |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 5412        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010283812 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.621      |\n",
            "|    explained_variance   | 0.00631     |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 21.1        |\n",
            "|    n_updates            | 77          |\n",
            "|    policy_gradient_loss | -0.00196    |\n",
            "|    value_loss           | 66.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 121         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1212        |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 5863        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024597622 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.524      |\n",
            "|    explained_variance   | 0.0323      |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 7.84        |\n",
            "|    n_updates            | 84          |\n",
            "|    policy_gradient_loss | -0.00425    |\n",
            "|    value_loss           | 35.2        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 121          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1214         |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 6314         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027106847 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.244        |\n",
            "|    entropy_loss         | -0.527       |\n",
            "|    explained_variance   | 0.0483       |\n",
            "|    learning_rate        | 0.000444     |\n",
            "|    loss                 | 147          |\n",
            "|    n_updates            | 91           |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    value_loss           | 131          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 126         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1216        |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 6765        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011746649 |\n",
            "|    clip_fraction        | 0.0351      |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.569      |\n",
            "|    explained_variance   | 0.0326      |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 45.3        |\n",
            "|    n_updates            | 98          |\n",
            "|    policy_gradient_loss | -0.0006     |\n",
            "|    value_loss           | 73.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 135          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1218         |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 7216         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.611354e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.244        |\n",
            "|    entropy_loss         | -0.609       |\n",
            "|    explained_variance   | 0.0272       |\n",
            "|    learning_rate        | 0.000444     |\n",
            "|    loss                 | 33.9         |\n",
            "|    n_updates            | 105          |\n",
            "|    policy_gradient_loss | 5.13e-05     |\n",
            "|    value_loss           | 61.1         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 719           |\n",
            "|    ep_rew_mean          | 135           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1220          |\n",
            "|    iterations           | 17            |\n",
            "|    time_elapsed         | 6             |\n",
            "|    total_timesteps      | 7667          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013457905 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.244         |\n",
            "|    entropy_loss         | -0.601        |\n",
            "|    explained_variance   | 0.00305       |\n",
            "|    learning_rate        | 0.000444      |\n",
            "|    loss                 | 43.7          |\n",
            "|    n_updates            | 112           |\n",
            "|    policy_gradient_loss | -0.000184     |\n",
            "|    value_loss           | 57.6          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 138         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1222        |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 8118        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005866372 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.624      |\n",
            "|    explained_variance   | 0.00625     |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 2.39        |\n",
            "|    n_updates            | 119         |\n",
            "|    policy_gradient_loss | -0.00182    |\n",
            "|    value_loss           | 64.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 719          |\n",
            "|    ep_rew_mean          | 138          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1224         |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 8569         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029379467 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.244        |\n",
            "|    entropy_loss         | -0.642       |\n",
            "|    explained_variance   | 0.0223       |\n",
            "|    learning_rate        | 0.000444     |\n",
            "|    loss                 | 6.5          |\n",
            "|    n_updates            | 126          |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    value_loss           | 51.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 138         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1225        |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 9020        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004184734 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.587      |\n",
            "|    explained_variance   | -0.0213     |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 4.85        |\n",
            "|    n_updates            | 133         |\n",
            "|    policy_gradient_loss | -0.00102    |\n",
            "|    value_loss           | 47.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 137         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1227        |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 9471        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013396201 |\n",
            "|    clip_fraction        | 0.0269      |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.543      |\n",
            "|    explained_variance   | 0.0504      |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 50          |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00214    |\n",
            "|    value_loss           | 36.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 719         |\n",
            "|    ep_rew_mean          | 137         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1228        |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 9922        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001012675 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.244       |\n",
            "|    entropy_loss         | -0.494      |\n",
            "|    explained_variance   | 0.0337      |\n",
            "|    learning_rate        | 0.000444    |\n",
            "|    loss                 | 15.1        |\n",
            "|    n_updates            | 147         |\n",
            "|    policy_gradient_loss | -0.000423   |\n",
            "|    value_loss           | 77          |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 719           |\n",
            "|    ep_rew_mean          | 142           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1230          |\n",
            "|    iterations           | 23            |\n",
            "|    time_elapsed         | 8             |\n",
            "|    total_timesteps      | 10373         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00018508724 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.244         |\n",
            "|    entropy_loss         | -0.466        |\n",
            "|    explained_variance   | 0.0289        |\n",
            "|    learning_rate        | 0.000444      |\n",
            "|    loss                 | 15.1          |\n",
            "|    n_updates            | 154           |\n",
            "|    policy_gradient_loss | 0.000752      |\n",
            "|    value_loss           | 59.4          |\n",
            "-------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2023-08-01 14:55:10,560] Trial 0 failed with parameters: {'n_steps': 451.12033220489013, 'gamma': 0.9617187267622725, 'learning_rate': 0.000443853526740911, 'ent_coef': 0.028552271773859387, 'cliprange': 0.2439260175845944, 'noptepochs': 7.791510724032618, 'lam': 0.9594901554244898} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Temp\\ipykernel_13956\\918136109.py\", line 79, in Optimize_PPO_agent\n",
            "    action, _ = model.predict(obs)\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\base_class.py\", line 555, in predict\n",
            "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\policies.py\", line 349, in predict\n",
            "    actions = self._predict(observation, deterministic=deterministic)\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\policies.py\", line 679, in _predict\n",
            "    return self.get_distribution(observation).get_actions(deterministic=deterministic)\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\policies.py\", line 714, in get_distribution\n",
            "    return self._get_action_dist_from_latent(latent_pi)\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\policies.py\", line 653, in _get_action_dist_from_latent\n",
            "    mean_actions = self.action_net(latent_pi)\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"C:\\Users\\12016\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "KeyboardInterrupt\n",
            "[W 2023-08-01 14:55:10,603] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\12016\\OneDrive\\Desktop\\School Work\\FinTrade\\PPOA2C_Model.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/School%20Work/FinTrade/PPOA2C_Model.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/School%20Work/FinTrade/PPOA2C_Model.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(Optimize_PPO_agent, n_trials \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
            "\u001b[1;32mc:\\Users\\12016\\OneDrive\\Desktop\\School Work\\FinTrade\\PPOA2C_Model.ipynb Cell 13\u001b[0m in \u001b[0;36mOptimize_PPO_agent\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/School%20Work/FinTrade/PPOA2C_Model.ipynb#X15sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/School%20Work/FinTrade/PPOA2C_Model.ipynb#X15sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mwhile\u001b[39;00m n_episodes \u001b[39m<\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/School%20Work/FinTrade/PPOA2C_Model.ipynb#X15sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     action, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(obs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/School%20Work/FinTrade/PPOA2C_Model.ipynb#X15sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     obs, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/School%20Work/FinTrade/PPOA2C_Model.ipynb#X15sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     reward_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\base_class.py:555\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[0;32m    536\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    537\u001b[0m     observation: Union[np\u001b[39m.\u001b[39mndarray, Dict[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    540\u001b[0m     deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    541\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, Optional[Tuple[np\u001b[39m.\u001b[39mndarray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]]:\n\u001b[0;32m    542\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[39m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[39m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 555\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mpredict(observation, state, episode_start, deterministic)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\policies.py:349\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    346\u001b[0m observation, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_to_tensor(observation)\n\u001b[0;32m    348\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 349\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(observation, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[0;32m    350\u001b[0m \u001b[39m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[0;32m    351\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mshape))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\policies.py:679\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[1;34m(self, observation, deterministic)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, observation: th\u001b[39m.\u001b[39mTensor, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    672\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[39m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[39m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_distribution(observation)\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\policies.py:714\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    712\u001b[0m features \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mextract_features(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpi_features_extractor)\n\u001b[0;32m    713\u001b[0m latent_pi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_extractor\u001b[39m.\u001b[39mforward_actor(features)\n\u001b[1;32m--> 714\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_action_dist_from_latent(latent_pi)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\policies.py:653\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_action_dist_from_latent\u001b[39m(\u001b[39mself\u001b[39m, latent_pi: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Distribution:\n\u001b[0;32m    647\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[39m    Retrieve action distribution given the latent codes.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \n\u001b[0;32m    650\u001b[0m \u001b[39m    :param latent_pi: Latent code for the actor\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[39m    :return: Action distribution\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 653\u001b[0m     mean_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_net(latent_pi)\n\u001b[0;32m    655\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m    656\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mproba_distribution(mean_actions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_std)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(Optimize_PPO_agent, n_trials = 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_steps': 47.69492578331755,\n",
              " 'gamma': 0.9210157662984991,\n",
              " 'learning_rate': 9.977870235715527e-05,\n",
              " 'ent_coef': 7.971129466598355e-06,\n",
              " 'cliprange': 0.3076116027483111,\n",
              " 'noptepochs': 5.248265181259201,\n",
              " 'lam': 0.9777987276354275}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lnLBB5H3yeQz",
        "outputId": "25dc2773-f382-446d-eac8-1c129fc3f80a"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'total_profit'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\12016\\OneDrive\\Desktop\\FinTrade\\PPOA2C_Model.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/FinTrade/PPOA2C_Model.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m qs\u001b[39m.\u001b[39mextend_pandas()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/FinTrade/PPOA2C_Model.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m net_worth \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(env\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mtotal_profit\u001b[39;49m\u001b[39m'\u001b[39;49m], index\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mindex[start_index\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:end_index])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/FinTrade/PPOA2C_Model.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m returns \u001b[39m=\u001b[39m net_worth\u001b[39m.\u001b[39mpct_change()\u001b[39m.\u001b[39miloc[\u001b[39m1\u001b[39m:]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12016/OneDrive/Desktop/FinTrade/PPOA2C_Model.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m qs\u001b[39m.\u001b[39mreports\u001b[39m.\u001b[39mfull(returns)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'total_profit'"
          ]
        }
      ],
      "source": [
        "qs.extend_pandas()\n",
        "\n",
        "net_worth = pd.Series(env.history['total_profit'], index=data.index[start_index+1:end_index])\n",
        "returns = net_worth.pct_change().iloc[1:]\n",
        "\n",
        "qs.reports.full(returns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-y_ANP2ygO5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.11 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "c66c414bb5828e35fb9401ff1a65441791869db0e134a48c3be4c6c28e754224"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
